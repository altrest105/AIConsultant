import os
import logging
from django.conf import settings
from faster_whisper import WhisperModel

logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏
WHISPER_MODEL = None


def get_model():
    global WHISPER_MODEL
    
    if WHISPER_MODEL is not None:
        return WHISPER_MODEL
    
    try:
        model_size = settings.STT_CONFIG.get("MODEL_SIZE", "large")
        gpu_compute_type = settings.STT_CONFIG.get("GPU_COMPUTE_TYPE", "float16")
        cpu_compute_type = settings.STT_CONFIG.get("CPU_COMPUTE_TYPE", "int8")

        # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU
        logger.info("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ Whisper –º–æ–¥–µ–ª–∏ –Ω–∞ GPU...")
        WHISPER_MODEL = WhisperModel(model_size, device="cuda", compute_type=gpu_compute_type)
        logger.info("‚úÖ Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ GPU")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞ GPU: {e}")
        try:
            # Fallback –Ω–∞ CPU
            logger.info("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ Whisper –º–æ–¥–µ–ª–∏ –Ω–∞ CPU...")
            WHISPER_MODEL = WhisperModel(model_size, device="cpu", compute_type=cpu_compute_type)
            logger.info("‚úÖ Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")
        except Exception as cpu_error:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {cpu_error}")
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å")
    
    return WHISPER_MODEL


def transcribe_audio(file_path):
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = get_model()
    
    try:
        language = settings.STT_CONFIG.get("LANGUAGE", "ru")
        beam_size = settings.STT_CONFIG.get("BEAM_SIZE", 5)
        vad_threshold = settings.STT_CONFIG.get("VAD_THRESHOLD", 0.5)
        vad_min_speech_duration_ms = settings.STT_CONFIG.get("VAD_MIN_SPEECH_DURATION_MS", 250)

        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
        segments, info = model.transcribe(
            file_path,
            language=language,
            beam_size=beam_size,
            vad_filter=True,
            vad_parameters={
                "threshold": vad_threshold,
                "min_speech_duration_ms": vad_min_speech_duration_ms,
            }
        )
        
        # –°–±–æ—Ä —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        text_parts = []
        for segment in segments:
            text_parts.append(segment.text.strip())
        
        text = ' '.join(text_parts)
        
        logger.info(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        return text
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}")
        raise